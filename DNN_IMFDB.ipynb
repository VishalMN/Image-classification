{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 100\n",
    "epochs = 30\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "#Extracting paths of all images in dataset along with labels\n",
    "dir = '/home/vishalmn/Omnamahshivaay/IMFDB_final'                                                                                                                                                                                                          \n",
    "images = []\n",
    "labels = []\n",
    "for root, dirs, files in os.walk(dir):\n",
    "    for name in files:\n",
    "        if name.endswith('.jpg'):\n",
    "            img = os.path.join(root, name)\n",
    "            images.append(img)\n",
    "            found = re.search('.*IMFDB_final/(.+?)/.*',root).group(1)\n",
    "            labels.append(found)\n",
    "            #print(found)\n",
    "            \n",
    "            \n",
    "image_dataset = []\n",
    "\n",
    "#Loading images from the dataset\n",
    "for image in images:\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.resize(img, (img_rows, img_cols))\n",
    "    img = img_to_array(img)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (img_rows, img_cols))\n",
    "    #img = img.reshape((img_rows,img_cols,1))\n",
    "    image_dataset.append(img)\n",
    "print(\"Successfully read images\")\n",
    "\n",
    "#Shuffling the dataset\n",
    "combine = list(zip(image_dataset,labels))\n",
    "random.shuffle(combine)\n",
    "image_dataset[:],labels[:] = zip(*combine)\n",
    "\n",
    "#Converting list to numpy array for feeding into model \n",
    "image_dataset = np.array(image_dataset, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    " \n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(image_dataset,\n",
    "    labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Datasets ',image_dataset.shape)\n",
    "print('x_train shape : ', x_train.shape)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols,3)\n",
    "    input_shape = (img_rows, img_cols,3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#Creating model and stacking up layers\n",
    "model = Sequential()\n",
    "#Layer 1, ie input layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "#Layer 2\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "#Layer 3\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "#Layer 4\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "#Layer 5\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Dropout(0.5))\n",
    "#Layer 6, ie output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Execution\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "#Final results\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
